{"cells":[{"cell_type":"markdown","metadata":{"id":"uj75cMRiwpym"},"source":["### **Overview**\n","\n","This notebook test the Decision Tree performance on the Walaris dataset as a feature based model.\n","It uses the same basic processing and thhe same split as the Mamba model. We call this \"Mamba compatible\".\n","\n","The notebook contains the feature extraction process, including the transformations and crafted features taken from them.\\\n","The train-val-test sets are created using the split done with reference to scale balancing.\\\n","This version is a unified version, with one model trained on samples of all durations. It is evaluated separately for each sample duration.\n","We use a 5-fold cross validation method to find the hyperparameters with best average performance on the validation set. A grid search using the relevant parameters is conducted.\\\n","After finding the hyperparameters, the model is trained on the entire training set and evaluiated on the test set. The results are saved for later analysis where the best model is chosen for the average result on the validation set.\\\n","Note that the dataset is balanced to contained the same representation of samples from all durations. This is somewhat different then the mamba case."]},{"cell_type":"markdown","metadata":{"id":"IFad3OUXiH7m"},"source":["### Imports and loading"]},{"cell_type":"code","source":["!pip install \"pandas<2\""],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Rg8ryPoqLn3W","executionInfo":{"status":"ok","timestamp":1715352583487,"user_tz":-180,"elapsed":48085,"user":{"displayName":"אילה רענן","userId":"13457086393139042919"}},"outputId":"8b5406fd-83bf-4fa7-9146-641264037ce8"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting pandas<2\n","  Downloading pandas-1.5.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.1 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.1/12.1 MB\u001b[0m \u001b[31m26.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas<2) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<2) (2023.4)\n","Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from pandas<2) (1.25.2)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas<2) (1.16.0)\n","Installing collected packages: pandas\n","  Attempting uninstall: pandas\n","    Found existing installation: pandas 2.0.3\n","    Uninstalling pandas-2.0.3:\n","      Successfully uninstalled pandas-2.0.3\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","cudf-cu12 24.4.1 requires pandas<2.2.2dev0,>=2.0, but you have pandas 1.5.3 which is incompatible.\n","google-colab 1.0.0 requires pandas==2.0.3, but you have pandas 1.5.3 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed pandas-1.5.3\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2489,"status":"ok","timestamp":1715352658964,"user":{"displayName":"אילה רענן","userId":"13457086393139042919"},"user_tz":-180},"id":"q2hR_rZ4hcwY","outputId":"58075a43-64e3-42d3-885d-9eb733fc5342"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"]}],"source":["# imports\n","\n","import io\n","import os\n","import sys\n","from datetime import datetime\n","import pickle\n","import warnings\n","warnings.filterwarnings('ignore')\n","import json\n","import matplotlib.pyplot as plt\n","import numpy as np\n","from scipy.fft import fft\n","import pandas as pd\n","import seaborn as sns\n","from scipy import interpolate\n","from scipy.interpolate import interp1d\n","from scipy.spatial.distance import cdist\n","from scipy.stats import pearsonr\n","\n","# Machine Learning\n","from sklearn.decomposition import PCA\n","from sklearn.model_selection import train_test_split, StratifiedKFold\n","from sklearn.pipeline import make_pipeline\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.svm import SVC\n","from sklearn import tree\n","from sklearn.tree import DecisionTreeClassifier\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n","from sklearn.metrics import classification_report\n","from sklearn.utils import class_weight\n","import xgboost as xgb\n","\n","from google.colab import drive\n","drive.mount('/content/drive/')\n","# helper files\n","sys.path.append('/content/drive/MyDrive/Final Project UAV/')\n","from UAV_project_preprocessing_and_visualization_helper_functions_full import *"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5,"status":"ok","timestamp":1715352608362,"user":{"displayName":"אילה רענן","userId":"13457086393139042919"},"user_tz":-180},"id":"EP0cLHeSozdF","outputId":"04d826c8-0fa9-4cdd-d774-8c20ec24d5ca"},"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/Final Project UAV\n"]}],"source":["cd /content/drive/MyDrive/Final Project UAV/"]},{"cell_type":"markdown","source":["### Segmentation"],"metadata":{"id":"EmuJtXUpZujJ"}},{"cell_type":"markdown","source":["Assume interpolation of dt = 40 msec.\\\n","For example: a sequence of 5 seconds is equivalent to 25*5 = 125"],"metadata":{"id":"RleKlQDgaQHZ"}},{"cell_type":"code","source":["folder = 'track_data'"],"metadata":{"id":"CMND-GMFfeaM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def get_unique_time_and_value(time_vec, value_vec):\n","  unique_time_vec = []\n","  unique_val_vec = []\n","  for i in range(len(time_vec)):\n","    if i == 0 or time_vec[i] != time_vec[i-1]:\n","      num_dup = 1\n","      unique_time_vec.append(time_vec[i])\n","      unique_val_vec.append(value_vec[i])\n","    else:\n","      num_dup = num_dup + 1\n","      unique_val_vec[-1] = ((num_dup-1)*unique_val_vec[-1] + value_vec[i])/num_dup\n","  return np.array(unique_time_vec), np.array(unique_val_vec)"],"metadata":{"id":"EnQe1O7HPnfZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def segment_file_by_time(file_path, samples_config):\n","  '''This function segments a file according to the configurations.\n","  It performs cleaning and interpolation as needed and derives the data to obtain the velocity and acceleration and add them as inputs\n","  It also produces the time interval vector and the local Std (scale) vector, which is used for normaliation of the loss function.\n","  '''\n","  sample_duration = samples_config['sample_duration']\n","  tt, xx, yy, zz, theta, phi, size_hor, size_ver, light_domain = raw_angles_data_from_json(file_path)\n","  theta, phi = convert_to_angles(xx, yy, zz)\n","  _, xx = get_unique_time_and_value(tt, xx)\n","  _, yy = get_unique_time_and_value(tt, yy)\n","  _, zz = get_unique_time_and_value(tt, zz)\n","  _, theta = get_unique_time_and_value(tt, theta)\n","  _, phi = get_unique_time_and_value(tt, phi)\n","  _, size_hor = get_unique_time_and_value(tt, size_hor)\n","  unique_tt, size_ver = get_unique_time_and_value(tt, size_ver)\n","  xx, yy, zz = clean_3D_data_w_split(unique_tt, xx, yy, zz, factor = 3, window = 5, threshold = -999)\n","  theta, phi = clean_2D_data_w_split(unique_tt, theta, phi, factor = 3, window = 5, threshold = -999)\n","  complete_sample = np.stack([unique_tt, xx, yy, zz, size_hor, size_ver]).T\n","\n","  #segmenting\n","  skip = samples_config['skip_duration']\n","  current_index = [0]\n","  end_index = np.nonzero(unique_tt>=unique_tt[0]+sample_duration)[0]\n","\n","  sub_samples = []\n","  while end_index.size:\n","      if end_index[0] - current_index[0] > samples_config['min_samples']: ### a threshold for a minimum number of datapoints in a sample\n","        sub_samples.append(complete_sample[current_index[0]:end_index[0], :])\n","      end_index = np.nonzero(unique_tt>=unique_tt[current_index[0]]+skip+sample_duration)[0]\n","      current_index = np.nonzero(unique_tt>=unique_tt[current_index[0]]+skip)[0]\n","\n","  return sub_samples, light_domain"],"metadata":{"id":"RL5aYuYSd0v9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["subfolders = os.listdir(\"track_data/\")\n","subf_dict = {i:subfolders[i] for i in range(len(subfolders))}\n","labels_dict = {subfolders[i]:i for i in range(len(subfolders))}"],"metadata":{"id":"uNSdEfjxoIdX"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Extract samples"],"metadata":{"id":"NSK_zw837Dox"}},{"cell_type":"code","source":["subf_dict"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6KbmQvmQbP3U","executionInfo":{"status":"ok","timestamp":1715352608838,"user_tz":-180,"elapsed":6,"user":{"displayName":"אילה רענן","userId":"13457086393139042919"}},"outputId":"3562b4db-7597-4cf3-b3ca-db2a6f260f04"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{0: 'airplane', 1: 'uav', 2: 'bird', 3: 'static-object'}"]},"metadata":{},"execution_count":9}]},{"cell_type":"code","source":["def extract_samples(folder, samples_config):\n","  #Extracts sample from an entire subfolder and returns it as a dict of subsamples by filename\n","  subfolders = os.listdir(folder)\n","  subfolders_list = [subfolders[i] for i in samples_config['subfolders_ind']]\n","\n","  samples_dict = {}\n","  samples_summary_dict = {}\n","\n","  for skip, subfolder in zip(samples_config['skip_durations'],subfolders_list):\n","      samples_config['skip_duration'] = skip\n","      print(subfolder)\n","      total_samples = 0\n","      subfolder_path = os.path.join(folder, subfolder)\n","      files = os.listdir(subfolder_path)\n","      for file in files:\n","          file_path = os.path.join(subfolder_path, file)\n","          sub_samples, light_domain = segment_file_by_time(file_path, samples_config)\n","          samples_dict[file] = sub_samples\n","          total_samples = total_samples + len(sub_samples)\n","      samples_summary_dict[subfolder] = total_samples\n","  print('samples summary:', samples_summary_dict)\n","  return samples_dict, samples_summary_dict"],"metadata":{"id":"o_AFCYTkh3Dw"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# samples_config = {\n","#     'sample_duration' : 15,\n","#     'overlap_factor' : 0.25, #not used here\n","#     'skip_durations' : [15, 15, 2, 40],\n","#     'skip_duration' : 15,\n","#     'subfolders_ind' : [0, 1, 2, 3],\n","#     'min_samples' : 10\n","# }\n","# # sample_durations = [25]\n","# # sample_durations = [3, 5, 10, 15, 20, 25]\n","# sample_durations = [5, 10, 15, 20, 25, 30, 60]\n","# # overlaps = [0, 0.25] #not used here for compatability with Mamba\n","# for dur in sample_durations:\n","#   print('Sample Duration = ', dur)\n","#   samples_config['sample_duration'] = dur\n","#   samples_dict, samples_summary_dict = extract_samples(folder, samples_config)\n","#   save_path = './Samples/samples_'+ str(dur) + '_M_compatible'\n","#   with open(save_path , 'wb') as f:\n","#       pickle.dump((samples_dict, samples_summary_dict), f)"],"metadata":{"id":"Suibu0DoFqWA"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Helper transformations and feature functions (temp - to be moved to file)"],"metadata":{"id":"cA3lSWL86zUn"}},{"cell_type":"code","source":["def return_span(series):\n","  return series.max() - series.min()"],"metadata":{"id":"zCbytSxp69qn"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def phi_theta_ratio(tt, data_theta, data_phi, pt_ratio_quants, dt=1, time_span = 3):\n","  \"\"\"returns the phi to theta min/max ratios and quantiles calculate for a rolling window of time_span\n","  \"\"\"\n","  new_tt = np.arange(tt[0], tt[-1]+dt, dt)\n","\n","  interp_data_theta = np.interp(new_tt, tt, data_theta)\n","  pd_data_theta = pd.Series(interp_data_theta)\n","  rolling_data_theta = pd_data_theta.rolling(time_span)\n","  span_theta = rolling_data_theta.apply(return_span)\n","\n","  interp_data_phi = np.interp(new_tt, tt, data_phi)\n","  pd_data_phi = pd.Series(interp_data_phi)\n","  rolling_data_phi = pd_data_phi.rolling(time_span)\n","  span_phi = rolling_data_phi.apply(return_span)\n","  span_ratios = np.arctan(span_phi/span_theta)\n","  span_ratios = span_ratios[~np.isnan(span_ratios)]\n","  span_ratios_quant = np.quantile(span_ratios, pt_ratio_quants)\n","\n","  return span_ratios.min(), span_ratios.max(), span_ratios_quant"],"metadata":{"id":"rr00aVkVePXg"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def PCA_angles_transformation(theta, phi):\n","  \"\"\"returns the data, rotated so that the principle axis of the data in the xy plane is on x\n","  \"\"\"\n","  tp_data = np.stack([theta, phi]).T\n","\n","  pca = PCA(n_components=2, svd_solver='full')\n","  angles_projected = pca.fit_transform(tp_data)\n","\n","  return angles_projected[:,0], angles_projected[:,1]\n","  # new_theta, new_phi = PCA_angles_transformation(cleaned_theta, cleaned_phi)"],"metadata":{"id":"gDei3W0x7_-K"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def angle_span_ratios(theta, phi):\n","  # returns the angle span ratios for the original data and the principle axes rotated data\n","  orig_ratio = (phi.max() - phi.min())/(theta.max() - theta.min())\n","  pca_theta, pca_phi = PCA_angles_transformation(theta, phi)\n","  pca_ratio = (pca_phi.max() - pca_phi.min())/(pca_theta.max() - pca_theta.min())\n","  return orig_ratio, pca_ratio"],"metadata":{"id":"fxOjmDRV_Q2r"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def smoothed(data, window = 5):\n","  \"\"\"\n","  Args:\n","    data: A one dimensional array of data.\n","    window: The window of the convolution used for low-pass filtering.\n","\n","  Returns:\n","    A smoothed version of the data\n","  \"\"\"\n","  # Run a low pass filter.\n","  padded_data = np.pad(data, (window//2, window//2), 'edge')\n","  smooth_data = np.convolve(padded_data, np.ones(window) / window, mode='valid')\n","  return smooth_data"],"metadata":{"id":"9PA7CITmDlvt"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def derive(theta_data, phi_data, time):\n","  # Derivation used for velocity and acceleration\n","  # Makes sure there are no inf or nan values\n","  t_der = (time[:-1] + time[1:])/2\n","  der_theta = np.diff(theta_data)/np.diff(time)\n","  inf_ind1 = np.where(np.isinf(der_theta))\n","  nan_ind1 = np.where(np.isnan(der_theta))\n","  der_phi = np.diff(phi_data)/np.diff(time)\n","  inf_ind2 = np.where(np.isinf(der_phi))\n","  nan_ind2 = np.where(np.isnan(der_phi))\n","  inf_inds = np.union1d(inf_ind1, inf_ind2)\n","  nan_inds = np.union1d(nan_ind1, nan_ind2)\n","  inds = np.union1d(inf_inds, nan_inds)\n","  mask = np.ones(len(t_der), dtype=bool)\n","  mask[inds] = False\n","\n","  return der_theta[mask], der_phi[mask], t_der[mask]"],"metadata":{"id":"ZiJd1Au-gMOz"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Extract features"],"metadata":{"id":"73loRkCF7vye"}},{"cell_type":"code","source":["#filter designed for UAV velocity profile\n","t1 = np.arange(2, 5, 0.04)\n","t2 = np.arange(5, 6, 0.04)\n","part1 = (0.5/5**2)*t1**2 + 0.5\n","part2 = 1 - 0.5*(t2-5)\n","filt1 = np.flip(np.hstack([part1, part2]))\n","t4 = np.arange(-5, -2, 0.04)\n","t3 = np.arange(-6, -5, 0.04)\n","part3 = -1 - 0.5*(t3+5)\n","part4 = -(0.5/5**2)*t4**2 - 0.5\n","filt2 = np.flip(np.hstack([part3, part4]))"],"metadata":{"id":"IoV6bPfHbZ6g"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def extract_features(sample):\n","  tt, xx, yy, zz, size_hor, size_ver = sample[:, 0], sample[:, 1], sample[:, 2], sample[:, 3], sample[:, 4], sample[:, 5]\n","  theta, phi = convert_to_angles(xx, yy, zz)\n","  # Basic transformations\n","  #standerdizing to start from 0\n","  phi = phi - phi[0]\n","  theta = theta - theta[0]\n","  # clean\n","  theta, phi = clean_2D_data_w_split(tt, theta, phi, factor = 3, window = 5, threshold = -999, replace_by = 'med')\n","\n","  # interpolate\n","  delta = 0.04\n","  interp_tt, interp_theta = interpolate_data(tt, theta, dt=delta, fixed = False)\n","  interp_tt, interp_phi = interpolate_data(tt, phi, dt=delta, fixed = False)\n","  # interp_tt, interp_xx = interpolate_data(tt, xx, dt=delta, fixed = False)\n","  # interp_tt, interp_yy = interpolate_data(tt, yy, dt=delta, fixed = False)\n","  # interp_tt, interp_zz = interpolate_data(tt, zz, dt=delta, fixed = False)\n","  interp_tt, interp_size_hor = interpolate_data(tt, size_hor, dt=delta, fixed = False)\n","  interp_tt, interp_size_ver = interpolate_data(tt, size_ver, dt=delta, fixed = False)\n","  fix_interp_tt, fix_interp_theta = interpolate_data(tt, theta, dt=delta, fixed = True)\n","  fix_interp_tt, fix_interp_phi = interpolate_data(tt, phi, dt=delta, fixed = True)\n","\n","  # derive\n","  interp_vel_theta, interp_vel_phi, interp_t_vel = derive(interp_theta, interp_phi, interp_tt)\n","  vel_theta, vel_phi, t_vel = derive(theta, phi, tt)\n","  abs_vel = np.sqrt(vel_theta**2 + vel_phi**2)\n","  acc_theta, acc_phi, t_acc = derive(vel_theta, vel_phi, t_vel)\n","  abs_acc = np.sqrt(acc_theta**2 + acc_phi**2)\n","  fix_vel_theta, fix_vel_phi, t_vel = derive(fix_interp_theta, fix_interp_phi, fix_interp_tt)\n","\n","  # rolling window smoothing\n","  s_theta = smoothed(theta, window = 5)\n","  s_phi = smoothed(phi, window = 5)\n","  delta = 0.04\n","  # interp_tt, s_interp_theta = interpolate_data(tt, s_theta, dt=delta, fixed = False)\n","  # interp_tt, s_interp_phi = interpolate_data(tt, s_phi, dt=delta, fixed = False)\n","  # s_vel_theta = np.diff(s_interp_theta)/np.diff(interp_tt)\n","  # s_vel_phi = np.diff(s_interp_phi)/np.diff(interp_tt)\n","  # s_abs_vel = np.sqrt(s_vel_theta**2 + s_vel_phi**2)\n","  s_vel_theta, s_vel_phi, s_t_vel = derive(s_theta, s_phi, tt)\n","  s_abs_vel = np.sqrt(s_vel_theta**2 + s_vel_phi**2)\n","  s_vel_theta, s_vel_phi, s_t_vel = derive(s_theta, s_phi, tt)\n","  s_abs_vel = np.sqrt(s_vel_theta**2 + s_vel_phi**2)\n","  s_acc_theta, s_acc_phi, s_t_acc = derive(s_vel_theta, s_vel_phi, s_t_vel)\n","  s_abs_acc = np.sqrt(s_acc_theta**2 + s_acc_phi**2)\n","\n","  # FEATURES\n","  returning_features = []\n","  feature_names = []\n","  # extreme values (scale dependent)\n","  max_size_hor = size_hor.max()\n","  max_size_ver = size_ver.max()\n","  max_elevation = phi.max()\n","  min_elevation = phi.min()\n","  max_theta_vel =  np.abs(vel_theta).max()\n","  max_phi_vel =  np.abs(vel_phi).max()\n","  max_vel = abs_vel.max()\n","  max_theta_acc =  np.abs(acc_theta).max()\n","  max_phi_acc =  np.abs(acc_phi).max()\n","  max_acc = abs_acc.max()\n","  returning_features.extend([max_elevation, min_elevation, max_theta_vel, max_phi_vel, max_vel, max_theta_acc, max_phi_acc, max_acc])\n","  feature_names.extend(['max_elevation', 'min_elevation', 'max_theta_vel', 'max_phi_vel', 'max_vel', 'max_theta_acc', 'max_phi_acc', 'max_acc'])\n","\n","  s_max_elevation = s_phi.max()\n","  s_min_elevation = s_phi.min()\n","  s_max_theta_vel = np.abs(s_vel_theta).max()\n","  s_max_phi_vel = np.abs(s_vel_phi).max()\n","  s_max_vel = s_abs_vel.max()\n","  s_med_vel = np.median(s_abs_vel)\n","  s_max_theta_acc = np.abs(s_acc_theta).max()\n","  s_max_phi_acc = np.abs(s_acc_phi).max()\n","  s_max_acc = s_abs_acc.max()\n","  s_med_acc = np.median(s_abs_acc)\n","  returning_features.extend([s_max_elevation, s_min_elevation, s_max_theta_vel, s_max_phi_vel, s_max_vel, s_max_theta_acc, s_max_phi_acc, s_max_acc])\n","  feature_names.extend(['s_max_elevation', 's_min_elevation', 's_max_theta_vel', 's_max_phi_vel', 's_max_vel', 's_max_theta_acc', 's_max_phi_acc', 's_max_acc'])\n","\n","  # statistics and noise\n","  theta_std = local_std(interp_theta, window = 10)\n","  phi_std = local_std(interp_phi, window = 10)\n","  theta_vel_std = local_std(interp_vel_theta, window = 10)\n","  phi_vel_std = local_std(interp_vel_phi, window = 10)\n","  returning_features.extend([theta_std, phi_std, theta_vel_std, phi_vel_std])\n","  feature_names.extend(['theta_std', 'phi_std', 'theta_vel_std', 'phi_vel_std'])\n","\n","  # span\n","  theta_span = theta.max() - theta.min()\n","  phi_span = phi.max() - phi.min()\n","  returning_features.extend([theta_span, phi_span])\n","  feature_names.extend(['theta_span', 'phi_span'])\n","\n","  # avg values\n","  med_elevation = np.median(phi)\n","  med_size_hor = np.median(size_hor)\n","  med_size_ver = np.median(size_ver)\n","  med_theta_vel =  np.median(vel_theta)\n","  med_phi_vel =  np.median(vel_phi)\n","  med_theta_acc =  np.median(acc_theta)\n","  med_phi_acc =  np.median(acc_phi)\n","  returning_features.extend([med_elevation, med_theta_vel, med_phi_vel, med_theta_acc, med_phi_acc, s_med_vel, s_med_acc])\n","  feature_names.extend(['med_elevation', 'med_theta_vel', 'med_phi_vel', 'med_theta_acc', 'med_phi_acc', 's_med_vel', 's_med_acc'])\n","\n","  # Bounding box data\n","  returning_features.extend([max_size_hor, max_size_ver, med_size_hor, med_size_ver])\n","  feature_names.extend(['max_size_hor', 'max_size_ver', 'med_size_hor', 'med_size_ver'])\n","\n","\n","  # correlations\n","  ascending_sig = np.max(np.convolve(fix_vel_phi/fix_vel_phi.max(), filt1, mode='valid'))\n","  decending_sig = np.max(np.convolve(fix_vel_phi/fix_vel_phi.min(), filt2, mode='valid'))\n","\n","  pt_vel_corr, _ = pearsonr(np.abs(vel_theta), np.abs(vel_phi))\n","  pt_acc_corr, _ = pearsonr(np.abs(acc_theta), np.abs(acc_phi))\n","\n","  returning_features.extend([ascending_sig, decending_sig, pt_vel_corr, pt_acc_corr])\n","  feature_names.extend(['ascending_sig', 'decending_sig', 'pt_vel_corr', 'pt_acc_corr'])\n","\n","  # FFT\n","\n","  # yf = fft(fix_vel_phi)\n","  # yf_trimmed_abs = np.abs(yf[0:len(yf)//2+1])\n","\n","  # ratios\n","  orig_ratio, pca_ratio = angle_span_ratios(theta, phi)\n","  std_vs_span = np.sqrt((theta_std**2 + phi_std**2)/(theta_span**2 + phi_span**2))\n","  returning_features.extend([orig_ratio, pca_ratio, std_vs_span])\n","  feature_names.extend(['orig_ratio', 'pca_ratio', 'std_vs_span'])\n","\n","  # scale independent features\n","  # measuring geometric curvature\n","\n","  discrete_angle_dist = np.sqrt(np.diff(interp_theta)**2 + np.diff(interp_phi)**2)\n","  cumsum_angles_dist = np.cumsum(discrete_angle_dist)\n","  path_total_length = cumsum_angles_dist[-1]\n","  cum_dist = np.hstack([0, cumsum_angles_dist])\n","\n","  angles = np.stack([interp_theta, interp_phi]).T\n","  eucl_dist = cdist(angles, angles, 'euclidean') + np.ones([len(interp_theta), len(interp_theta)])*1e-6 #added to avoid devision by 0\n","\n","  path_dist = np.abs(cum_dist[:, None] - cum_dist)\n","  dist_ratio = path_dist/eucl_dist\n","  distance_buffer = 5 #removing ratios of points close to one another, since this may be noisy\n","  all_curve_ratios = sum((dist_ratio[i,i+distance_buffer:].tolist() for i in range(dist_ratio.shape[0])), [])\n","  curve_quants = np.arange(0.1, 0.95, 0.1)\n","  curve_quantiles = np.quantile(all_curve_ratios, curve_quants)\n","  max_curve_ratio = np.max(all_curve_ratios)\n","  returning_features.extend([*curve_quantiles, max_curve_ratio])\n","  q_names = ['curve quant ' + str(round(q, 2)) for q in curve_quants]\n","  feature_names.extend(q_names + ['max_curve_ratio'])\n","\n","  # measuring angles ratios (quantiles):\n","  # e.g. object rising fast without changing azimuth, or changing azimuth without elevation\n","  pt_ratio_quants = np.arange(0.1, 0.95, 0.1)\n","  min_span_ratios, max_span_ratios, span_ratios_quant = phi_theta_ratio(tt, theta, phi, pt_ratio_quants, dt=1, time_span = 3)\n","  returning_features.extend([*span_ratios_quant, max_span_ratios, min_span_ratios])\n","  q_names = ['pt ratio quant ' + str(round(q, 2)) for q in pt_ratio_quants]\n","  feature_names.extend(q_names + ['max_span_ratios', 'min_span_ratios'])\n","\n","  # velocity and acceleration profiles (ratios)\n","  motion_quants = np.arange(0.1, 0.95, 0.1)\n","  vel_quantiles = np.quantile(s_abs_vel, motion_quants)\n","  vel_profile = vel_quantiles/s_med_vel\n","  acc_quantiles = np.quantile(s_abs_acc, motion_quants)\n","  acc_profile = acc_quantiles/s_med_acc\n","  q_vel_names = ['vel quant ' + str(round(q, 2)) for q in motion_quants]\n","  q_acc_names = ['acc quant ' + str(round(q, 2)) for q in motion_quants]\n","  returning_features.extend([*vel_profile, *acc_profile])\n","  feature_names.extend(q_vel_names + q_acc_names)\n","\n","  return returning_features, feature_names"],"metadata":{"id":"yEl_k3nM3aEf"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Prepare dataset"],"metadata":{"id":"QbUS6Eo373XT"}},{"cell_type":"code","source":["def prepare_dataset(split_config):\n","  print('collecting samples')\n","  subfolders_list = [subf_dict[i] for i in np.arange(4)]\n","  save_path = './Samples/samples_'+ str(split_config['sample_duration']) + '_M_compatible'\n","  with open(save_path , 'rb') as f:\n","    samples_dict, samples_summary_dict = pickle.load(f)\n","\n","  # files_labels = []\n","  all_samples = []\n","  samples_labels = []\n","  samples_filenames = []\n","  samples_light = []\n","  database_summary_dict = {}\n","\n","  for subfolder in subfolders_list:\n","    subfolder_path = os.path.join(folder, subfolder)\n","    files = os.listdir(subfolder_path) # Can also be taken from samples_dict keys\n","    # files_labels.extend([labels_dict[subfolder]]*len(files))\n","    n_subfolder_samples = 0\n","    for file in files:\n","      light_domain = file[:3]\n","      sub_samples = samples_dict[file]\n","      all_samples.extend(sub_samples)\n","      sub_labels = [labels_dict[subfolder]]*len(sub_samples)\n","      samples_labels.extend(sub_labels)\n","      sub_light = [light_domain]*len(sub_samples)\n","      samples_light.extend(sub_light)\n","      sub_file = [file]*len(sub_samples)\n","      samples_filenames.extend(sub_file)\n","      n_subfolder_samples = n_subfolder_samples + len(sub_samples)\n","    database_summary_dict[subfolder] = n_subfolder_samples\n","  print('extracting features')\n","  data = []\n","  for i, sample in enumerate(all_samples):\n","    data_row, features = extract_features(sample)\n","    data.append(data_row)\n","\n","  df = pd.DataFrame(data, columns=features)\n","  df['light'] = samples_light\n","  df['file'] = samples_filenames\n","  df['label'] = samples_labels\n","\n","  print('Done')\n","  return df, features"],"metadata":{"id":"jdQPqKaEdya_"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Split"],"metadata":{"id":"XFURuAe4rRag"}},{"cell_type":"code","source":["def split_by_Mamba_files(df, df_test):\n","  subfolders = ['airplane', 'uav', 'bird', 'static-object']\n","  all_test_files = []\n","  all_train_files = []\n","  for subfolder in subfolders:\n","    save_split_path = './Samples/mamba_samples_'+ subfolder + '_split0.2'\n","    with open(save_split_path , 'rb') as f:\n","      files_train, files_val, files_test = pickle.load(f)\n","      all_test_files.extend(list(files_test))\n","      all_train_files.extend(list(files_train))\n","      all_train_files.extend(list(files_val))\n","\n","  test_df = df_test[df_test['file'].isin(all_test_files)]\n","  train_df = df[df['file'].isin(all_train_files)] #Mamba used a validation set, but here we append it to the train set\n","  return train_df, test_df"],"metadata":{"id":"TTqfn03uUz61"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def split_by_files(df, df0, split_config):\n","  files = np.unique(df['file'].values)\n","  files_ind = [np.where(df['file'].values == f)[0][0] for f in files]\n","  files_labels = df['label'].values[files_ind]\n","  rs = split_config['random_state']\n","  ts = split_config['test_split_files']\n","  files_train, files_test = train_test_split(files, test_size=ts, random_state=rs, stratify=files_labels)\n","  train_df = df[df['file'].isin(files_train)]\n","  test_df = df0[df0['file'].isin(files_test)]\n","  return train_df, test_df"],"metadata":{"id":"fMADz8abAfCm"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(labels_dict)\n","print(subf_dict)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"04l2VYPKQRUF","executionInfo":{"status":"ok","timestamp":1715352609584,"user_tz":-180,"elapsed":2,"user":{"displayName":"אילה רענן","userId":"13457086393139042919"}},"outputId":"5332c7a8-0db6-4234-9c98-47a60ab68eb2"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["{'airplane': 0, 'uav': 1, 'bird': 2, 'static-object': 3}\n","{0: 'airplane', 1: 'uav', 2: 'bird', 3: 'static-object'}\n"]}]},{"cell_type":"markdown","source":["### Evaluation"],"metadata":{"id":"aRHy7rCLBl73"}},{"cell_type":"code","source":["def evaluate(labels, predictions, caption, plot_cm , print_scores):\n","\n","  classes = np.union1d(labels, predictions)\n","  tick_names = [subf_dict[c] for c in classes]\n","  # Confusion Matrix - Multi class\n","  cm = confusion_matrix(labels, predictions)\n","  disp = ConfusionMatrixDisplay(confusion_matrix=cm,\n","                               display_labels=tick_names)\n","  if plot_cm:\n","    disp.plot()\n","    disp.ax_.set_title(caption)\n","    plt.show()\n","\n","  # Scores #\n","  # f1_s = f1_score(labels, predictions, sample_weight=None, average = 'weighted', zero_division='warn')\n","  report = classification_report(labels, predictions, target_names = tick_names, output_dict=True, digits=3, zero_division = 0)\n","\n","  f1_all = report['weighted avg']['f1-score']\n","\n","  if print_scores == True:\n","      print(classification_report(labels, predictions, target_names = tick_names,digits=3, zero_division = 0))\n","      # print(f1_s)\n","      print('Average F1 score for all classes = ', f1_all)\n","      print('------------------------')\n","      print('UAV report')\n","      print('------------------------')\n","      print('precision = ', report['uav']['precision'])\n","      print('recall = ', report['uav']['recall'])\n","      print('F1 = ', report['uav']['f1-score'])\n","      print('support = ', report['uav']['support'])\n","\n","  return report"],"metadata":{"id":"OcD3qzt_FUIv"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Experiments"],"metadata":{"id":"ngvs1istUO2a"}},{"cell_type":"code","source":["record_columns = ['datetime', 'Sample Duration', 'Test Files', 'Split Config', 'Features Config', 'Model', 'Model Config', 'Evaluation Report', 'UAV precision', 'UAV recall', 'UAV f1', 'Total f1']\n","exp_record = pd.DataFrame(columns = record_columns)"],"metadata":{"id":"C-JfJdNhbq-N"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def conf2str(split_config, features_config):\n","  conf_str = 'sd' + str(split_config['sample_duration']) \\\n","  +'ms' + str(split_config['min_samples']) \\\n","  +'f_date' + str(features_config['date'])\n","  return conf_str"],"metadata":{"id":"rTu7JS3JMywC"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["features_dict = {\n","    'extremum' : np.arange(0,16),\n","    'std' : np.arange(16,20),\n","    'span' : np.arange(20,22),\n","    'med' : np.arange(22,29),\n","    'bbox' : np.arange(29,33),\n","    'corr_sig' : np.arange(33,37),\n","    'full_ratio' : np.arange(37,40),\n","    'curve' : np.arange(40,50),\n","    'pt_ratio' : np.arange(50,61),\n","    'vel_acc_profile' : np.arange(61,79)\n","}"],"metadata":{"id":"XoqR7TgInQyg"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def get_datasets(split_config, features_config):\n","  conf_str = conf2str(split_config, features_config)\n","  database_path = './Features Databases/database_'+ conf_str\n","  if os.path.isfile(database_path):\n","    with open(database_path , 'rb') as f:\n","      df, features = pickle.load(f)\n","      # print('Loading dataset')\n","  else:\n","    df, features = prepare_dataset(split_config)\n","    with open(database_path , 'wb') as f:\n","      pickle.dump((df, features), f)\n","\n","  # #retrieving 0 overlap matching df\n","  # ol0_config = split_config.copy()\n","  # ol0_config['overlap_factor'] = 0\n","  # conf_str = conf2str(ol0_config, features_config)\n","\n","  # database0_path = './Features Databases/database_'+ conf_str\n","  # if os.path.isfile(database0_path):\n","  #   with open(database0_path , 'rb') as f:\n","  #     df0, features = pickle.load(f)\n","  #     # print('Loading dataset')\n","  # else:\n","  #   df0, features = prepare_dataset(ol0_config)\n","  #   with open(database0_path , 'wb') as f:\n","  #     pickle.dump((df0, features), f)\n","  return df, features"],"metadata":{"id":"AeEmiAjM7akc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["record_columns = ['datetime', 'Sample Duration', 'Test Files', 'Split Config', 'Features Config', 'Model', 'Model Config', 'Evaluation Report', 'UAV precision', 'UAV recall', 'UAV f1', 'Total f1']\n","exp_record = pd.DataFrame(columns = record_columns)\n","\n","split_config = {\n","    'sample_duration' : 5,\n","    # 'overlap_factor' : 0.25,\n","    'subfolders_ind' : [0, 1, 2, 3],\n","    'min_samples' : 10,\n","    'random_state' : 42,\n","    'test_split_files' : 0.2, # 2 for n files\n","    'kfold' : 5\n","  }\n","\n","features_config = {\n","    'date' : 20_1_2024,\n","    'extremum' : True,\n","    'std' : True,\n","    'span' : True,\n","    'med' : True,\n","    'bbox' : True,\n","    'corr_sig' : True,\n","    'full_ratio' : True,\n","    'curve' : True,\n","    'pt_ratio' : True,\n","    'vel_acc_profile' : True\n","  }\n","\n","\n","dt_config = {\n","    'max_depth' : 10,\n","    'model_random_state' : 42\n","  }\n","\n","# split_random_states = [32]\n","# sample_durations = [20]\n","# max_depth = [10]\n","\n","model_random_states = [42]\n","split_random_states = [42]\n","train_sample_durations = [5, 10, 30]\n","test_sample_durations = [5, 10, 15, 20, 25, 30]\n","# sample_durations = [10]\n","max_depth = [5, 7, 10, None]\n","\n","model_name = 'DT'\n","model_config = dt_config\n","\n","now = datetime.now()\n","date_time = now.strftime(\"%m/%d/%Y, %H:%M:%S\")\n","#gather data from all datasets and equalize\n","## combine train data\n","dur_weight = []\n","datasets = []\n","for dur in train_sample_durations:\n","  split_config['sample_duration'] = dur\n","  datasets.append(get_datasets(split_config, features_config))\n","  dur_weight.append(len(datasets[-1][0]))\n","\n","max_weight = max(dur_weight)\n","\n","#empty dataframe\n","df = pd.DataFrame(columns = datasets[0][0].columns)\n","for i in range(len(dur_weight)):\n","  #appending full original size - 0 overlap\n","  dataset_dur = datasets[i][0]\n","  df = df.append(dataset_dur)\n","  #appending leftover to balance\n","  leftover = max_weight - len(dataset_dur)\n","  df = df.append(dataset_dur.sample(leftover, replace = True))\n","\n","# ## combine test data\n","# dur_weight = []\n","# datasets = []\n","# for dur in test_sample_durations:\n","#   split_config['sample_duration'] = dur\n","#   datasets.append(get_datasets(split_config, features_config))\n","#   dur_weight.append(len(datasets[-1][0]))\n","\n","# max_weight = max(dur_weight)\n","\n","# #empty dataframe\n","# df_test = pd.DataFrame(columns = datasets[0][0].columns)\n","# for i in range(len(dur_weight)):\n","#   #appending full original size - 0 overlap\n","#   dataset_dur = datasets[i][0]\n","#   df_test = df_test.append(dataset_dur)\n","#   #appending leftover to balance\n","#   leftover = max_weight - len(dataset_dur)\n","#   df_test = df_test.append(dataset_dur.sample(leftover, replace = True))\n","\n","train_df, _ = split_by_Mamba_files(df, df)\n","\n","# for mrs in model_random_states:\n","#   model_config['model_random_state'] = mrs\n","#   for rs in split_random_states:\n","#     split_config['random_state'] = rs\n","      # for dur in sample_durations:\n","      #   split_config['sample_duration'] = dur\n","for depth in max_depth:\n","  model_config['max_depth'] = depth\n","  # print(split_config)\n","  # print(model_config)\n","  #Don't change split_config beyond this point\n","  # _d1, df0, features = get_datasets(split_config, features_config)\n","  # train_df, test_df = split_by_files(df, df0, split_config)\n","\n","  feature_columns = np.empty(0)\n","  for key in features_config.keys():\n","    if features_config[key] == True:\n","      feature_columns = np.hstack([feature_columns, features_dict[key]])\n","\n","  # train_df = train_df_0.sample(frac = 1, random_state = model_config['model_random_state']) #shuffled df (note - same rs as the model)\n","  train_df = train_df[train_df['label'].isin(split_config['subfolders_ind'])] # removing the folders we don't want to analyze (in split_config)\n","  train_df = train_df.sample(frac = 1, random_state = model_config['model_random_state']) #shuffled df (note - same rs as the model)\n","  train = train_df.iloc[:, feature_columns].values\n","  # test_df = test_df[test_df['label'].isin(split_config['subfolders_ind'])] # removing the folders we don't want to analyze (in split_config)\n","  # test = test_df.iloc[:, feature_columns].values\n","  train_labels = train_df['label'].values.astype(np.int64)\n","  train_classes_weights = class_weight.compute_sample_weight(class_weight='balanced', y=train_labels)\n","  # test_labels = test_df['label'].values.astype(np.int64)\n","\n","  #kfold cross validation\n","  # splitting needs to be done according to filenames to not have train and val samples from the same file\n","  files = np.unique(train_df['file'].values)\n","  files_ind = [np.where(train_df['file'].values == f)[0][0] for f in files]\n","  files_labels = train_df['label'].values[files_ind].astype(np.int64)\n","  # use stratified Kfold for imbalance handling\n","  skf = StratifiedKFold(n_splits=split_config['kfold'])\n","  skfold_ind = skf.split(files, files_labels)\n","  uav_precision = []\n","  uav_recall = []\n","  uav_f1 = []\n","  weighted_f1 = []\n","  for (train_ind, val_ind) in skfold_ind:\n","    train_files = files[train_ind]\n","    k_train_df = train_df[train_df['file'].isin(train_files)]\n","    k_train_df = k_train_df.sample(frac = 1, random_state = model_config['model_random_state']) #shuffled df (note - same rs as the model)\n","    k_train_labels = k_train_df['label'].values.astype(np.int64)\n","    k_train = k_train_df.iloc[:, feature_columns].values\n","    k_train_classes_weights = class_weight.compute_sample_weight(class_weight='balanced', y=k_train_labels)\n","\n","    val_files = files[val_ind]\n","    # k_val_df = df0[df0['file'].isin(val_files)] # taking calculations from samples without overlap\n","    k_val_df = train_df[train_df['file'].isin(val_files)]\n","    k_val_df = k_val_df.sample(frac = 1, random_state = model_config['model_random_state']) #shuffled df (note - same rs as the model)\n","    k_val_labels = k_val_df['label'].values.astype(np.int64)\n","    k_val = k_val_df.iloc[:, feature_columns].values\n","\n","    if model_name == 'DT':\n","      dtr = DecisionTreeClassifier(max_depth=model_config['max_depth'], random_state=model_config['model_random_state'], class_weight = 'balanced')\n","      dtr.fit(k_train, k_train_labels)\n","      k_predictions = dtr.predict(k_val)\n","\n","    k_report = evaluate(k_val_labels, k_predictions, model_name+'_depth_'+str(model_config['max_depth']), False , False)\n","    uav_precision.append(k_report['uav']['precision'])\n","    uav_recall.append(k_report['uav']['recall'])\n","    uav_f1.append(k_report['uav']['f1-score'])\n","    weighted_f1.append(k_report['weighted avg']['f1-score'])\n","\n","  uav_precision_m = sum(uav_precision)/len(uav_precision)\n","  uav_recall_m = sum(uav_recall)/len(uav_recall)\n","  uav_f1_m = sum(uav_f1)/len(uav_f1)\n","  weighted_f1_m = sum(weighted_f1)/len(weighted_f1)\n","\n","  # print('Fitting all train and test evaluation')\n","  dtr = DecisionTreeClassifier(max_depth=model_config['max_depth'], random_state=model_config['model_random_state'])\n","  dtr.fit(train, train_labels)\n","\n","  for dur in test_sample_durations:\n","    split_config['sample_duration'] = dur\n","    df_test, features = get_datasets(split_config, features_config)\n","    _d2, test_df = split_by_Mamba_files(df, df_test)\n","    test_df = test_df[test_df['label'].isin(split_config['subfolders_ind'])] # removing the folders we don't want to analyze (in split_config)\n","    test = test_df.iloc[:, feature_columns].values\n","    test_labels = test_df['label'].values.astype(np.int64)\n","    predictions = dtr.predict(test)\n","    test_report = evaluate(test_labels, predictions, model_name+'_depth_'+str(model_config['max_depth']), False , False)\n","\n","    # wrong_ind = np.where(predictions != test_labels)\n","    # print('wrong on:')\n","    # wrong_files = np.unique(test_df['file'].iloc[wrong_ind])\n","    # print(wrong_files)\n","    ## print(test_df['file'].iloc[wrong_ind])\n","    test_files = np.unique(test_df['file'])\n","\n","    exp_record.loc[len(exp_record)] = [date_time, dur, test_files, split_config.copy(), features_config, model_name, model_config.copy(),\n","                      test_report, uav_precision_m, uav_recall_m, uav_f1_m, weighted_f1_m]"],"metadata":{"id":"QfM7V3qc6I8A"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# features"],"metadata":{"id":"yMxHO201ojBC"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["date_time_ = str(date_time).replace(\"/\",\"_\")\n","# results_path = './Features Extraction Results/features_extraction_results_' + date_time_\n","results_path = './Features Extraction Results unified durations/features_extraction_results_' + date_time_\n","\n","with open(results_path , 'wb') as f:\n","  pickle.dump(exp_record, f)"],"metadata":{"id":"MRJtp4JPMCVH"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["exp_record"],"metadata":{"id":"3xPTz6ogGTQG","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1715352686091,"user_tz":-180,"elapsed":304,"user":{"displayName":"אילה רענן","userId":"13457086393139042919"}},"outputId":"fbca0636-6312-4164-ff2c-4713a0636190"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["                datetime  Sample Duration  \\\n","0   05/10/2024, 14:51:06                5   \n","1   05/10/2024, 14:51:06               10   \n","2   05/10/2024, 14:51:06               15   \n","3   05/10/2024, 14:51:06               20   \n","4   05/10/2024, 14:51:06               25   \n","5   05/10/2024, 14:51:06               30   \n","6   05/10/2024, 14:51:06                5   \n","7   05/10/2024, 14:51:06               10   \n","8   05/10/2024, 14:51:06               15   \n","9   05/10/2024, 14:51:06               20   \n","10  05/10/2024, 14:51:06               25   \n","11  05/10/2024, 14:51:06               30   \n","12  05/10/2024, 14:51:06                5   \n","13  05/10/2024, 14:51:06               10   \n","14  05/10/2024, 14:51:06               15   \n","15  05/10/2024, 14:51:06               20   \n","16  05/10/2024, 14:51:06               25   \n","17  05/10/2024, 14:51:06               30   \n","18  05/10/2024, 14:51:06                5   \n","19  05/10/2024, 14:51:06               10   \n","20  05/10/2024, 14:51:06               15   \n","21  05/10/2024, 14:51:06               20   \n","22  05/10/2024, 14:51:06               25   \n","23  05/10/2024, 14:51:06               30   \n","\n","                                           Test Files  \\\n","0   [NIR_airplane_20230603-534_20230603-010658.jso...   \n","1   [NIR_airplane_20230603-534_20230603-010658.jso...   \n","2   [NIR_airplane_20231023-19489_20231023-191158.j...   \n","3   [NIR_airplane_20231024-10120_20231024-030841.j...   \n","4   [NIR_airplane_20231024-10120_20231024-030841.j...   \n","5   [NIR_airplane_20231024-10120_20231024-030841.j...   \n","6   [NIR_airplane_20230603-534_20230603-010658.jso...   \n","7   [NIR_airplane_20230603-534_20230603-010658.jso...   \n","8   [NIR_airplane_20231023-19489_20231023-191158.j...   \n","9   [NIR_airplane_20231024-10120_20231024-030841.j...   \n","10  [NIR_airplane_20231024-10120_20231024-030841.j...   \n","11  [NIR_airplane_20231024-10120_20231024-030841.j...   \n","12  [NIR_airplane_20230603-534_20230603-010658.jso...   \n","13  [NIR_airplane_20230603-534_20230603-010658.jso...   \n","14  [NIR_airplane_20231023-19489_20231023-191158.j...   \n","15  [NIR_airplane_20231024-10120_20231024-030841.j...   \n","16  [NIR_airplane_20231024-10120_20231024-030841.j...   \n","17  [NIR_airplane_20231024-10120_20231024-030841.j...   \n","18  [NIR_airplane_20230603-534_20230603-010658.jso...   \n","19  [NIR_airplane_20230603-534_20230603-010658.jso...   \n","20  [NIR_airplane_20231023-19489_20231023-191158.j...   \n","21  [NIR_airplane_20231024-10120_20231024-030841.j...   \n","22  [NIR_airplane_20231024-10120_20231024-030841.j...   \n","23  [NIR_airplane_20231024-10120_20231024-030841.j...   \n","\n","                                         Split Config  \\\n","0   {'sample_duration': 5, 'subfolders_ind': [0, 1...   \n","1   {'sample_duration': 10, 'subfolders_ind': [0, ...   \n","2   {'sample_duration': 15, 'subfolders_ind': [0, ...   \n","3   {'sample_duration': 20, 'subfolders_ind': [0, ...   \n","4   {'sample_duration': 25, 'subfolders_ind': [0, ...   \n","5   {'sample_duration': 30, 'subfolders_ind': [0, ...   \n","6   {'sample_duration': 5, 'subfolders_ind': [0, 1...   \n","7   {'sample_duration': 10, 'subfolders_ind': [0, ...   \n","8   {'sample_duration': 15, 'subfolders_ind': [0, ...   \n","9   {'sample_duration': 20, 'subfolders_ind': [0, ...   \n","10  {'sample_duration': 25, 'subfolders_ind': [0, ...   \n","11  {'sample_duration': 30, 'subfolders_ind': [0, ...   \n","12  {'sample_duration': 5, 'subfolders_ind': [0, 1...   \n","13  {'sample_duration': 10, 'subfolders_ind': [0, ...   \n","14  {'sample_duration': 15, 'subfolders_ind': [0, ...   \n","15  {'sample_duration': 20, 'subfolders_ind': [0, ...   \n","16  {'sample_duration': 25, 'subfolders_ind': [0, ...   \n","17  {'sample_duration': 30, 'subfolders_ind': [0, ...   \n","18  {'sample_duration': 5, 'subfolders_ind': [0, 1...   \n","19  {'sample_duration': 10, 'subfolders_ind': [0, ...   \n","20  {'sample_duration': 15, 'subfolders_ind': [0, ...   \n","21  {'sample_duration': 20, 'subfolders_ind': [0, ...   \n","22  {'sample_duration': 25, 'subfolders_ind': [0, ...   \n","23  {'sample_duration': 30, 'subfolders_ind': [0, ...   \n","\n","                                      Features Config Model  \\\n","0   {'date': 2012024, 'extremum': True, 'std': Tru...    DT   \n","1   {'date': 2012024, 'extremum': True, 'std': Tru...    DT   \n","2   {'date': 2012024, 'extremum': True, 'std': Tru...    DT   \n","3   {'date': 2012024, 'extremum': True, 'std': Tru...    DT   \n","4   {'date': 2012024, 'extremum': True, 'std': Tru...    DT   \n","5   {'date': 2012024, 'extremum': True, 'std': Tru...    DT   \n","6   {'date': 2012024, 'extremum': True, 'std': Tru...    DT   \n","7   {'date': 2012024, 'extremum': True, 'std': Tru...    DT   \n","8   {'date': 2012024, 'extremum': True, 'std': Tru...    DT   \n","9   {'date': 2012024, 'extremum': True, 'std': Tru...    DT   \n","10  {'date': 2012024, 'extremum': True, 'std': Tru...    DT   \n","11  {'date': 2012024, 'extremum': True, 'std': Tru...    DT   \n","12  {'date': 2012024, 'extremum': True, 'std': Tru...    DT   \n","13  {'date': 2012024, 'extremum': True, 'std': Tru...    DT   \n","14  {'date': 2012024, 'extremum': True, 'std': Tru...    DT   \n","15  {'date': 2012024, 'extremum': True, 'std': Tru...    DT   \n","16  {'date': 2012024, 'extremum': True, 'std': Tru...    DT   \n","17  {'date': 2012024, 'extremum': True, 'std': Tru...    DT   \n","18  {'date': 2012024, 'extremum': True, 'std': Tru...    DT   \n","19  {'date': 2012024, 'extremum': True, 'std': Tru...    DT   \n","20  {'date': 2012024, 'extremum': True, 'std': Tru...    DT   \n","21  {'date': 2012024, 'extremum': True, 'std': Tru...    DT   \n","22  {'date': 2012024, 'extremum': True, 'std': Tru...    DT   \n","23  {'date': 2012024, 'extremum': True, 'std': Tru...    DT   \n","\n","                                     Model Config  \\\n","0      {'max_depth': 5, 'model_random_state': 42}   \n","1      {'max_depth': 5, 'model_random_state': 42}   \n","2      {'max_depth': 5, 'model_random_state': 42}   \n","3      {'max_depth': 5, 'model_random_state': 42}   \n","4      {'max_depth': 5, 'model_random_state': 42}   \n","5      {'max_depth': 5, 'model_random_state': 42}   \n","6      {'max_depth': 7, 'model_random_state': 42}   \n","7      {'max_depth': 7, 'model_random_state': 42}   \n","8      {'max_depth': 7, 'model_random_state': 42}   \n","9      {'max_depth': 7, 'model_random_state': 42}   \n","10     {'max_depth': 7, 'model_random_state': 42}   \n","11     {'max_depth': 7, 'model_random_state': 42}   \n","12    {'max_depth': 10, 'model_random_state': 42}   \n","13    {'max_depth': 10, 'model_random_state': 42}   \n","14    {'max_depth': 10, 'model_random_state': 42}   \n","15    {'max_depth': 10, 'model_random_state': 42}   \n","16    {'max_depth': 10, 'model_random_state': 42}   \n","17    {'max_depth': 10, 'model_random_state': 42}   \n","18  {'max_depth': None, 'model_random_state': 42}   \n","19  {'max_depth': None, 'model_random_state': 42}   \n","20  {'max_depth': None, 'model_random_state': 42}   \n","21  {'max_depth': None, 'model_random_state': 42}   \n","22  {'max_depth': None, 'model_random_state': 42}   \n","23  {'max_depth': None, 'model_random_state': 42}   \n","\n","                                    Evaluation Report  UAV precision  \\\n","0   {'airplane': {'precision': 0.5871559633027523,...       0.683353   \n","1   {'airplane': {'precision': 0.7037037037037037,...       0.683353   \n","2   {'airplane': {'precision': 0.6764705882352942,...       0.683353   \n","3   {'airplane': {'precision': 0.6981132075471698,...       0.683353   \n","4   {'airplane': {'precision': 0.7272727272727273,...       0.683353   \n","5   {'airplane': {'precision': 0.75, 'recall': 0.8...       0.683353   \n","6   {'airplane': {'precision': 0.7530864197530864,...       0.679125   \n","7   {'airplane': {'precision': 0.8484848484848485,...       0.679125   \n","8   {'airplane': {'precision': 0.8979591836734694,...       0.679125   \n","9   {'airplane': {'precision': 0.9722222222222222,...       0.679125   \n","10  {'airplane': {'precision': 0.96875, 'recall': ...       0.679125   \n","11  {'airplane': {'precision': 0.9285714285714286,...       0.679125   \n","12  {'airplane': {'precision': 0.6741573033707865,...       0.678942   \n","13  {'airplane': {'precision': 0.7857142857142857,...       0.678942   \n","14  {'airplane': {'precision': 0.8333333333333334,...       0.678942   \n","15  {'airplane': {'precision': 0.9, 'recall': 0.83...       0.678942   \n","16  {'airplane': {'precision': 0.918918918918919, ...       0.678942   \n","17  {'airplane': {'precision': 0.90625, 'recall': ...       0.678942   \n","18  {'airplane': {'precision': 0.75, 'recall': 0.8...       0.669168   \n","19  {'airplane': {'precision': 0.8333333333333334,...       0.669168   \n","20  {'airplane': {'precision': 0.8823529411764706,...       0.669168   \n","21  {'airplane': {'precision': 0.875, 'recall': 0....       0.669168   \n","22  {'airplane': {'precision': 0.9166666666666666,...       0.669168   \n","23  {'airplane': {'precision': 0.90625, 'recall': ...       0.669168   \n","\n","    UAV recall    UAV f1  Total f1  \n","0     0.751033  0.707195  0.779083  \n","1     0.751033  0.707195  0.779083  \n","2     0.751033  0.707195  0.779083  \n","3     0.751033  0.707195  0.779083  \n","4     0.751033  0.707195  0.779083  \n","5     0.751033  0.707195  0.779083  \n","6     0.790678  0.725507  0.802599  \n","7     0.790678  0.725507  0.802599  \n","8     0.790678  0.725507  0.802599  \n","9     0.790678  0.725507  0.802599  \n","10    0.790678  0.725507  0.802599  \n","11    0.790678  0.725507  0.802599  \n","12    0.784496  0.719548  0.795836  \n","13    0.784496  0.719548  0.795836  \n","14    0.784496  0.719548  0.795836  \n","15    0.784496  0.719548  0.795836  \n","16    0.784496  0.719548  0.795836  \n","17    0.784496  0.719548  0.795836  \n","18    0.784553  0.714395  0.793216  \n","19    0.784553  0.714395  0.793216  \n","20    0.784553  0.714395  0.793216  \n","21    0.784553  0.714395  0.793216  \n","22    0.784553  0.714395  0.793216  \n","23    0.784553  0.714395  0.793216  "],"text/html":["\n","  <div id=\"df-405d5603-bd90-48f7-926a-c7a8a5fb185b\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>datetime</th>\n","      <th>Sample Duration</th>\n","      <th>Test Files</th>\n","      <th>Split Config</th>\n","      <th>Features Config</th>\n","      <th>Model</th>\n","      <th>Model Config</th>\n","      <th>Evaluation Report</th>\n","      <th>UAV precision</th>\n","      <th>UAV recall</th>\n","      <th>UAV f1</th>\n","      <th>Total f1</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>05/10/2024, 14:51:06</td>\n","      <td>5</td>\n","      <td>[NIR_airplane_20230603-534_20230603-010658.jso...</td>\n","      <td>{'sample_duration': 5, 'subfolders_ind': [0, 1...</td>\n","      <td>{'date': 2012024, 'extremum': True, 'std': Tru...</td>\n","      <td>DT</td>\n","      <td>{'max_depth': 5, 'model_random_state': 42}</td>\n","      <td>{'airplane': {'precision': 0.5871559633027523,...</td>\n","      <td>0.683353</td>\n","      <td>0.751033</td>\n","      <td>0.707195</td>\n","      <td>0.779083</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>05/10/2024, 14:51:06</td>\n","      <td>10</td>\n","      <td>[NIR_airplane_20230603-534_20230603-010658.jso...</td>\n","      <td>{'sample_duration': 10, 'subfolders_ind': [0, ...</td>\n","      <td>{'date': 2012024, 'extremum': True, 'std': Tru...</td>\n","      <td>DT</td>\n","      <td>{'max_depth': 5, 'model_random_state': 42}</td>\n","      <td>{'airplane': {'precision': 0.7037037037037037,...</td>\n","      <td>0.683353</td>\n","      <td>0.751033</td>\n","      <td>0.707195</td>\n","      <td>0.779083</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>05/10/2024, 14:51:06</td>\n","      <td>15</td>\n","      <td>[NIR_airplane_20231023-19489_20231023-191158.j...</td>\n","      <td>{'sample_duration': 15, 'subfolders_ind': [0, ...</td>\n","      <td>{'date': 2012024, 'extremum': True, 'std': Tru...</td>\n","      <td>DT</td>\n","      <td>{'max_depth': 5, 'model_random_state': 42}</td>\n","      <td>{'airplane': {'precision': 0.6764705882352942,...</td>\n","      <td>0.683353</td>\n","      <td>0.751033</td>\n","      <td>0.707195</td>\n","      <td>0.779083</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>05/10/2024, 14:51:06</td>\n","      <td>20</td>\n","      <td>[NIR_airplane_20231024-10120_20231024-030841.j...</td>\n","      <td>{'sample_duration': 20, 'subfolders_ind': [0, ...</td>\n","      <td>{'date': 2012024, 'extremum': True, 'std': Tru...</td>\n","      <td>DT</td>\n","      <td>{'max_depth': 5, 'model_random_state': 42}</td>\n","      <td>{'airplane': {'precision': 0.6981132075471698,...</td>\n","      <td>0.683353</td>\n","      <td>0.751033</td>\n","      <td>0.707195</td>\n","      <td>0.779083</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>05/10/2024, 14:51:06</td>\n","      <td>25</td>\n","      <td>[NIR_airplane_20231024-10120_20231024-030841.j...</td>\n","      <td>{'sample_duration': 25, 'subfolders_ind': [0, ...</td>\n","      <td>{'date': 2012024, 'extremum': True, 'std': Tru...</td>\n","      <td>DT</td>\n","      <td>{'max_depth': 5, 'model_random_state': 42}</td>\n","      <td>{'airplane': {'precision': 0.7272727272727273,...</td>\n","      <td>0.683353</td>\n","      <td>0.751033</td>\n","      <td>0.707195</td>\n","      <td>0.779083</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>05/10/2024, 14:51:06</td>\n","      <td>30</td>\n","      <td>[NIR_airplane_20231024-10120_20231024-030841.j...</td>\n","      <td>{'sample_duration': 30, 'subfolders_ind': [0, ...</td>\n","      <td>{'date': 2012024, 'extremum': True, 'std': Tru...</td>\n","      <td>DT</td>\n","      <td>{'max_depth': 5, 'model_random_state': 42}</td>\n","      <td>{'airplane': {'precision': 0.75, 'recall': 0.8...</td>\n","      <td>0.683353</td>\n","      <td>0.751033</td>\n","      <td>0.707195</td>\n","      <td>0.779083</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>05/10/2024, 14:51:06</td>\n","      <td>5</td>\n","      <td>[NIR_airplane_20230603-534_20230603-010658.jso...</td>\n","      <td>{'sample_duration': 5, 'subfolders_ind': [0, 1...</td>\n","      <td>{'date': 2012024, 'extremum': True, 'std': Tru...</td>\n","      <td>DT</td>\n","      <td>{'max_depth': 7, 'model_random_state': 42}</td>\n","      <td>{'airplane': {'precision': 0.7530864197530864,...</td>\n","      <td>0.679125</td>\n","      <td>0.790678</td>\n","      <td>0.725507</td>\n","      <td>0.802599</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>05/10/2024, 14:51:06</td>\n","      <td>10</td>\n","      <td>[NIR_airplane_20230603-534_20230603-010658.jso...</td>\n","      <td>{'sample_duration': 10, 'subfolders_ind': [0, ...</td>\n","      <td>{'date': 2012024, 'extremum': True, 'std': Tru...</td>\n","      <td>DT</td>\n","      <td>{'max_depth': 7, 'model_random_state': 42}</td>\n","      <td>{'airplane': {'precision': 0.8484848484848485,...</td>\n","      <td>0.679125</td>\n","      <td>0.790678</td>\n","      <td>0.725507</td>\n","      <td>0.802599</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>05/10/2024, 14:51:06</td>\n","      <td>15</td>\n","      <td>[NIR_airplane_20231023-19489_20231023-191158.j...</td>\n","      <td>{'sample_duration': 15, 'subfolders_ind': [0, ...</td>\n","      <td>{'date': 2012024, 'extremum': True, 'std': Tru...</td>\n","      <td>DT</td>\n","      <td>{'max_depth': 7, 'model_random_state': 42}</td>\n","      <td>{'airplane': {'precision': 0.8979591836734694,...</td>\n","      <td>0.679125</td>\n","      <td>0.790678</td>\n","      <td>0.725507</td>\n","      <td>0.802599</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>05/10/2024, 14:51:06</td>\n","      <td>20</td>\n","      <td>[NIR_airplane_20231024-10120_20231024-030841.j...</td>\n","      <td>{'sample_duration': 20, 'subfolders_ind': [0, ...</td>\n","      <td>{'date': 2012024, 'extremum': True, 'std': Tru...</td>\n","      <td>DT</td>\n","      <td>{'max_depth': 7, 'model_random_state': 42}</td>\n","      <td>{'airplane': {'precision': 0.9722222222222222,...</td>\n","      <td>0.679125</td>\n","      <td>0.790678</td>\n","      <td>0.725507</td>\n","      <td>0.802599</td>\n","    </tr>\n","    <tr>\n","      <th>10</th>\n","      <td>05/10/2024, 14:51:06</td>\n","      <td>25</td>\n","      <td>[NIR_airplane_20231024-10120_20231024-030841.j...</td>\n","      <td>{'sample_duration': 25, 'subfolders_ind': [0, ...</td>\n","      <td>{'date': 2012024, 'extremum': True, 'std': Tru...</td>\n","      <td>DT</td>\n","      <td>{'max_depth': 7, 'model_random_state': 42}</td>\n","      <td>{'airplane': {'precision': 0.96875, 'recall': ...</td>\n","      <td>0.679125</td>\n","      <td>0.790678</td>\n","      <td>0.725507</td>\n","      <td>0.802599</td>\n","    </tr>\n","    <tr>\n","      <th>11</th>\n","      <td>05/10/2024, 14:51:06</td>\n","      <td>30</td>\n","      <td>[NIR_airplane_20231024-10120_20231024-030841.j...</td>\n","      <td>{'sample_duration': 30, 'subfolders_ind': [0, ...</td>\n","      <td>{'date': 2012024, 'extremum': True, 'std': Tru...</td>\n","      <td>DT</td>\n","      <td>{'max_depth': 7, 'model_random_state': 42}</td>\n","      <td>{'airplane': {'precision': 0.9285714285714286,...</td>\n","      <td>0.679125</td>\n","      <td>0.790678</td>\n","      <td>0.725507</td>\n","      <td>0.802599</td>\n","    </tr>\n","    <tr>\n","      <th>12</th>\n","      <td>05/10/2024, 14:51:06</td>\n","      <td>5</td>\n","      <td>[NIR_airplane_20230603-534_20230603-010658.jso...</td>\n","      <td>{'sample_duration': 5, 'subfolders_ind': [0, 1...</td>\n","      <td>{'date': 2012024, 'extremum': True, 'std': Tru...</td>\n","      <td>DT</td>\n","      <td>{'max_depth': 10, 'model_random_state': 42}</td>\n","      <td>{'airplane': {'precision': 0.6741573033707865,...</td>\n","      <td>0.678942</td>\n","      <td>0.784496</td>\n","      <td>0.719548</td>\n","      <td>0.795836</td>\n","    </tr>\n","    <tr>\n","      <th>13</th>\n","      <td>05/10/2024, 14:51:06</td>\n","      <td>10</td>\n","      <td>[NIR_airplane_20230603-534_20230603-010658.jso...</td>\n","      <td>{'sample_duration': 10, 'subfolders_ind': [0, ...</td>\n","      <td>{'date': 2012024, 'extremum': True, 'std': Tru...</td>\n","      <td>DT</td>\n","      <td>{'max_depth': 10, 'model_random_state': 42}</td>\n","      <td>{'airplane': {'precision': 0.7857142857142857,...</td>\n","      <td>0.678942</td>\n","      <td>0.784496</td>\n","      <td>0.719548</td>\n","      <td>0.795836</td>\n","    </tr>\n","    <tr>\n","      <th>14</th>\n","      <td>05/10/2024, 14:51:06</td>\n","      <td>15</td>\n","      <td>[NIR_airplane_20231023-19489_20231023-191158.j...</td>\n","      <td>{'sample_duration': 15, 'subfolders_ind': [0, ...</td>\n","      <td>{'date': 2012024, 'extremum': True, 'std': Tru...</td>\n","      <td>DT</td>\n","      <td>{'max_depth': 10, 'model_random_state': 42}</td>\n","      <td>{'airplane': {'precision': 0.8333333333333334,...</td>\n","      <td>0.678942</td>\n","      <td>0.784496</td>\n","      <td>0.719548</td>\n","      <td>0.795836</td>\n","    </tr>\n","    <tr>\n","      <th>15</th>\n","      <td>05/10/2024, 14:51:06</td>\n","      <td>20</td>\n","      <td>[NIR_airplane_20231024-10120_20231024-030841.j...</td>\n","      <td>{'sample_duration': 20, 'subfolders_ind': [0, ...</td>\n","      <td>{'date': 2012024, 'extremum': True, 'std': Tru...</td>\n","      <td>DT</td>\n","      <td>{'max_depth': 10, 'model_random_state': 42}</td>\n","      <td>{'airplane': {'precision': 0.9, 'recall': 0.83...</td>\n","      <td>0.678942</td>\n","      <td>0.784496</td>\n","      <td>0.719548</td>\n","      <td>0.795836</td>\n","    </tr>\n","    <tr>\n","      <th>16</th>\n","      <td>05/10/2024, 14:51:06</td>\n","      <td>25</td>\n","      <td>[NIR_airplane_20231024-10120_20231024-030841.j...</td>\n","      <td>{'sample_duration': 25, 'subfolders_ind': [0, ...</td>\n","      <td>{'date': 2012024, 'extremum': True, 'std': Tru...</td>\n","      <td>DT</td>\n","      <td>{'max_depth': 10, 'model_random_state': 42}</td>\n","      <td>{'airplane': {'precision': 0.918918918918919, ...</td>\n","      <td>0.678942</td>\n","      <td>0.784496</td>\n","      <td>0.719548</td>\n","      <td>0.795836</td>\n","    </tr>\n","    <tr>\n","      <th>17</th>\n","      <td>05/10/2024, 14:51:06</td>\n","      <td>30</td>\n","      <td>[NIR_airplane_20231024-10120_20231024-030841.j...</td>\n","      <td>{'sample_duration': 30, 'subfolders_ind': [0, ...</td>\n","      <td>{'date': 2012024, 'extremum': True, 'std': Tru...</td>\n","      <td>DT</td>\n","      <td>{'max_depth': 10, 'model_random_state': 42}</td>\n","      <td>{'airplane': {'precision': 0.90625, 'recall': ...</td>\n","      <td>0.678942</td>\n","      <td>0.784496</td>\n","      <td>0.719548</td>\n","      <td>0.795836</td>\n","    </tr>\n","    <tr>\n","      <th>18</th>\n","      <td>05/10/2024, 14:51:06</td>\n","      <td>5</td>\n","      <td>[NIR_airplane_20230603-534_20230603-010658.jso...</td>\n","      <td>{'sample_duration': 5, 'subfolders_ind': [0, 1...</td>\n","      <td>{'date': 2012024, 'extremum': True, 'std': Tru...</td>\n","      <td>DT</td>\n","      <td>{'max_depth': None, 'model_random_state': 42}</td>\n","      <td>{'airplane': {'precision': 0.75, 'recall': 0.8...</td>\n","      <td>0.669168</td>\n","      <td>0.784553</td>\n","      <td>0.714395</td>\n","      <td>0.793216</td>\n","    </tr>\n","    <tr>\n","      <th>19</th>\n","      <td>05/10/2024, 14:51:06</td>\n","      <td>10</td>\n","      <td>[NIR_airplane_20230603-534_20230603-010658.jso...</td>\n","      <td>{'sample_duration': 10, 'subfolders_ind': [0, ...</td>\n","      <td>{'date': 2012024, 'extremum': True, 'std': Tru...</td>\n","      <td>DT</td>\n","      <td>{'max_depth': None, 'model_random_state': 42}</td>\n","      <td>{'airplane': {'precision': 0.8333333333333334,...</td>\n","      <td>0.669168</td>\n","      <td>0.784553</td>\n","      <td>0.714395</td>\n","      <td>0.793216</td>\n","    </tr>\n","    <tr>\n","      <th>20</th>\n","      <td>05/10/2024, 14:51:06</td>\n","      <td>15</td>\n","      <td>[NIR_airplane_20231023-19489_20231023-191158.j...</td>\n","      <td>{'sample_duration': 15, 'subfolders_ind': [0, ...</td>\n","      <td>{'date': 2012024, 'extremum': True, 'std': Tru...</td>\n","      <td>DT</td>\n","      <td>{'max_depth': None, 'model_random_state': 42}</td>\n","      <td>{'airplane': {'precision': 0.8823529411764706,...</td>\n","      <td>0.669168</td>\n","      <td>0.784553</td>\n","      <td>0.714395</td>\n","      <td>0.793216</td>\n","    </tr>\n","    <tr>\n","      <th>21</th>\n","      <td>05/10/2024, 14:51:06</td>\n","      <td>20</td>\n","      <td>[NIR_airplane_20231024-10120_20231024-030841.j...</td>\n","      <td>{'sample_duration': 20, 'subfolders_ind': [0, ...</td>\n","      <td>{'date': 2012024, 'extremum': True, 'std': Tru...</td>\n","      <td>DT</td>\n","      <td>{'max_depth': None, 'model_random_state': 42}</td>\n","      <td>{'airplane': {'precision': 0.875, 'recall': 0....</td>\n","      <td>0.669168</td>\n","      <td>0.784553</td>\n","      <td>0.714395</td>\n","      <td>0.793216</td>\n","    </tr>\n","    <tr>\n","      <th>22</th>\n","      <td>05/10/2024, 14:51:06</td>\n","      <td>25</td>\n","      <td>[NIR_airplane_20231024-10120_20231024-030841.j...</td>\n","      <td>{'sample_duration': 25, 'subfolders_ind': [0, ...</td>\n","      <td>{'date': 2012024, 'extremum': True, 'std': Tru...</td>\n","      <td>DT</td>\n","      <td>{'max_depth': None, 'model_random_state': 42}</td>\n","      <td>{'airplane': {'precision': 0.9166666666666666,...</td>\n","      <td>0.669168</td>\n","      <td>0.784553</td>\n","      <td>0.714395</td>\n","      <td>0.793216</td>\n","    </tr>\n","    <tr>\n","      <th>23</th>\n","      <td>05/10/2024, 14:51:06</td>\n","      <td>30</td>\n","      <td>[NIR_airplane_20231024-10120_20231024-030841.j...</td>\n","      <td>{'sample_duration': 30, 'subfolders_ind': [0, ...</td>\n","      <td>{'date': 2012024, 'extremum': True, 'std': Tru...</td>\n","      <td>DT</td>\n","      <td>{'max_depth': None, 'model_random_state': 42}</td>\n","      <td>{'airplane': {'precision': 0.90625, 'recall': ...</td>\n","      <td>0.669168</td>\n","      <td>0.784553</td>\n","      <td>0.714395</td>\n","      <td>0.793216</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-405d5603-bd90-48f7-926a-c7a8a5fb185b')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-405d5603-bd90-48f7-926a-c7a8a5fb185b button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-405d5603-bd90-48f7-926a-c7a8a5fb185b');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-2cc2e634-7aa2-46fc-b532-f764de8a44ca\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-2cc2e634-7aa2-46fc-b532-f764de8a44ca')\"\n","            title=\"Suggest charts\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-2cc2e634-7aa2-46fc-b532-f764de8a44ca button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","\n","  <div id=\"id_6c274c2c-f817-493e-aeb5-5324343c1f72\">\n","    <style>\n","      .colab-df-generate {\n","        background-color: #E8F0FE;\n","        border: none;\n","        border-radius: 50%;\n","        cursor: pointer;\n","        display: none;\n","        fill: #1967D2;\n","        height: 32px;\n","        padding: 0 0 0 0;\n","        width: 32px;\n","      }\n","\n","      .colab-df-generate:hover {\n","        background-color: #E2EBFA;\n","        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","        fill: #174EA6;\n","      }\n","\n","      [theme=dark] .colab-df-generate {\n","        background-color: #3B4455;\n","        fill: #D2E3FC;\n","      }\n","\n","      [theme=dark] .colab-df-generate:hover {\n","        background-color: #434B5C;\n","        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","        fill: #FFFFFF;\n","      }\n","    </style>\n","    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('exp_record')\"\n","            title=\"Generate code using this dataframe.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n","  </svg>\n","    </button>\n","    <script>\n","      (() => {\n","      const buttonEl =\n","        document.querySelector('#id_6c274c2c-f817-493e-aeb5-5324343c1f72 button.colab-df-generate');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      buttonEl.onclick = () => {\n","        google.colab.notebook.generateWithVariable('exp_record');\n","      }\n","      })();\n","    </script>\n","  </div>\n","\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","variable_name":"exp_record","summary":"{\n  \"name\": \"exp_record\",\n  \"rows\": 24,\n  \"fields\": [\n    {\n      \"column\": \"datetime\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"05/10/2024, 14:51:06\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Sample Duration\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 8,\n        \"min\": 5,\n        \"max\": 30,\n        \"num_unique_values\": 6,\n        \"samples\": [\n          5\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Test Files\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Split Config\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Features Config\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Model\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"DT\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Model Config\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Evaluation Report\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"UAV precision\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.005315498183161296,\n        \"min\": 0.6691681900186147,\n        \"max\": 0.6833529239122458,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          0.6791251837822901\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"UAV recall\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.015929616567989312,\n        \"min\": 0.7510330982157608,\n        \"max\": 0.7906784280623289,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          0.7906784280623289\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"UAV f1\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.006877770109399143,\n        \"min\": 0.7071951227571673,\n        \"max\": 0.7255072427180294,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          0.7255072427180294\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Total f1\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.008750460259023858,\n        \"min\": 0.779082821060628,\n        \"max\": 0.8025990428024528,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          0.8025990428024528\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"}},"metadata":{},"execution_count":34}]},{"cell_type":"code","source":["exp_record.iloc[0]['Evaluation Report']"],"metadata":{"id":"XoN0aN2hjH5Y","executionInfo":{"status":"ok","timestamp":1715352693692,"user_tz":-180,"elapsed":414,"user":{"displayName":"אילה רענן","userId":"13457086393139042919"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"20d5e0e3-d7cc-4e91-c775-bf12df37477f"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'airplane': {'precision': 0.5871559633027523,\n","  'recall': 0.9411764705882353,\n","  'f1-score': 0.7231638418079096,\n","  'support': 68},\n"," 'uav': {'precision': 0.7424242424242424,\n","  'recall': 0.5104166666666666,\n","  'f1-score': 0.6049382716049382,\n","  'support': 96},\n"," 'bird': {'precision': 0.8765432098765432,\n","  'recall': 0.797752808988764,\n","  'f1-score': 0.8352941176470587,\n","  'support': 89},\n"," 'static-object': {'precision': 0.9345794392523364,\n","  'recall': 0.9090909090909091,\n","  'f1-score': 0.9216589861751152,\n","  'support': 110},\n"," 'accuracy': 0.7823691460055097,\n"," 'macro avg': {'precision': 0.7851757137139687,\n","  'recall': 0.7896092138336438,\n","  'f1-score': 0.7712638043087555,\n","  'support': 363},\n"," 'weighted avg': {'precision': 0.804450183950644,\n","  'recall': 0.7823691460055097,\n","  'f1-score': 0.7795396150602282,\n","  'support': 363}}"]},"metadata":{},"execution_count":35}]}],"metadata":{"colab":{"provenance":[{"file_id":"155q1Fp-p5PP400ILI4ZdsfSVEWPYLgKv","timestamp":1715351997026},{"file_id":"14QL5I9LZ5bB3Y8raoaxSDoJWoNsMQ0uR","timestamp":1714914564476},{"file_id":"1QJ6YWUDCpKXoOq4VuQhdxffcC0PP1_AL","timestamp":1714383760720},{"file_id":"1r7p9VanU_m81qruh02RxfDhdsHbCnxHh","timestamp":1714383724037},{"file_id":"1r3QlF2dWJaA7LVwNG0NcHRBC7RAv-28R","timestamp":1704878410179},{"file_id":"1_etuvholW7g3X9SlbPZDu8d1cWIRUl-H","timestamp":1704450125309},{"file_id":"1motfF6rUUOGXhgrlE2CqgTQgjET8nvBQ","timestamp":1704356485850},{"file_id":"1BEZz0DElbumDJld8D-nA0DTSHSCKoxge","timestamp":1703350819753},{"file_id":"1OS076JBuQIYw2q3GOhVDLf3iQTMlHm0u","timestamp":1702562147127},{"file_id":"1A4ATexl9-Yz1pi-J4qIaeBIAdxAOloq8","timestamp":1702135302257},{"file_id":"1AqHpw3FlTGarVQSH1zfD5Kw8hUsgXyeN","timestamp":1702111543738},{"file_id":"1KZW2Q_CH5wo9_Uv0M5pfVKwPtVhMMhDH","timestamp":1701809788329}],"toc_visible":true,"authorship_tag":"ABX9TyN3FHPHdgkumqQqhfFRrRC5"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}